# -*- coding: utf-8 -*-
"""2_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EEHDLDF749haxXIsKj-j-mNJbobzVNvL
"""

"""
Problem 2.4

Implement the perceptron algorithm and use it to perform classification on the 
IRIS PLANT DATABASE data as follows: Examine whether the data of each class are 
linearly separable from the data of the combined remaining classes (e.g. if the 
Iris Setosa data are linearly separable from the combined Iris Versicolor and 
Iris Virginica data). 
"""
import numpy as np

"""
Functions
"""

"""
Loads the data set and converts the feature vector to floats.
Parameter:
-filename: The path to the dataset file
Returns:
-The dataset as an ndarray 
-The labels of the classes in a list 
-The number of features
"""
def load_dataset(filename):
    dataset = []
    with open(filename) as file:
        for line in file:
            line = line.rstrip().split(",") #For every line of the data file delete the /n character and split the string into a list
            
            #Convert the stings into floats (for the sepal and petal lenghts)
            for i in range(0,len(line)-1):
                line[i] = float(line[i])
            if len(line) > 1:
                dataset.append(line)
    
    dataset = np.array(dataset) #Convert list to ndarray
    class_labels = np.unique(dataset[:, -1]) #Get the labels of the classes

    return dataset, class_labels, len(dataset[0,:-1]) #Return the dataset, the labels of the classes and the number of features


"""
Change the labels: 1 for the class under study, -1 for the other two classes.
Parameter:
-dataset: The whole datatset
-class_labels: The labels of the classes in a list 
-class_label: The label of the class under study
Returns:
- The dataset with its labels changed.
"""
def change_labels(dataset, class_labels, class_label):
    dataset_cp = dataset.copy()
    label_index = np.where(class_labels == class_label)
    temp = np.where(dataset_cp[:, -1] == class_labels[label_index], 1, -1)
    dataset_cp[:, -1] = temp
    return dataset_cp


"""
Implementation of the Perceptron algorithm for they weight estimation.
Paramateres:
-dataset: The dataset with the changed labels
-num_features: The number of features
-epochs: The max limit of epochs
Returns:
-The weight vector without the bias term
-The bias
"""
def train_weights(dataset, num_features, epochs = 1000):
    weights = np.zeros(num_features + 1) #Create an array of length number of features + 1(bias) to store the weights

    x_vector = np.array(dataset[:, :-1]) #Create an array of the features
    x_vector = np.hstack((x_vector, np.ones((x_vector.shape[0],1)) * -1)) #Add a column of -1's

    y_vector = np.array(dataset[:, -1]).reshape(x_vector.shape[0],1) #Create an array of the classes of each feature vector 

    target_x = x_vector * y_vector #Create the t*x array

    for epoch in range(0, epochs):     #For as long as the epoch number is lower than the limit

        errors = 0

        #Create the t*w*x vector
        for row in target_x:
            twx = np.dot(weights, row)

            #If it is smaller or equal to zero add an error and change the weights
            if twx <= 0.0:
                errors += 1
                weights = weights + row

        #If the number of errors after an epoch is equal to zero:
            #Stop the iteration
            #This class is linear separable
        if errors == 0:
            print("Converged when epoch = " + str(epoch + 1))
            print("This class is linear separable")
            break

        #If the number of errors isn't equal to zero and the number of epochs reached the limit:
            #Stop the iteration
            #This class is not linear separable
        if errors != 0 and epoch >= epochs -1:
            print("Failed to converge - This class is NOT linear separable")
            
    print("Epoch " +  str(epoch + 1) + ", errors = " + str(errors))
    return weights[:-1], weights[-1]

dataset, labels, num_features= load_dataset("iris.data")

for label in labels: #For each class
    print("Checking for class:", label)
    temp_dataset = change_labels(dataset, labels, label)
    temp_dataset = temp_dataset.astype(np.float)
    weights, w0 = train_weights(temp_dataset, num_features)
    print('weights: ', weights)
    print('bias(w0): ', w0)
    print()